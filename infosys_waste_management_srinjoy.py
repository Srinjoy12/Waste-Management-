# -*- coding: utf-8 -*-
"""Infosys waste management Srinjoy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GPWm-tHBC4RflVln0suC4Xfo0IXytQuG
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

from google.colab import files
uploaded = files.upload()

csv_filename = list(uploaded.keys())[0]
df = pd.read_csv(csv_filename)

df

df.isnull().sum()

df.describe()

df.dtypes

df.duplicated().sum()

df['waste_type'].unique()

df['waste_type'].value_counts()

import matplotlib.pyplot as plt

df['waste_type'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Distribution of Waste Types')
plt.xlabel('Waste Type')
plt.ylabel('Count')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
numeric_data = df.select_dtypes(include=np.number)
plt.figure(figsize=(10, 6))
sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

df['timestamp'] = pd.to_datetime(df['timestamp'])

plt.figure(figsize=(6, 4))
sns.boxplot(x=df['waste_type'], y=df['moisture_property'])
plt.title('Box Plot of Moisture Property by Waste Type')
plt.xlabel('Waste Type')
plt.ylabel('Moisture Property')
plt.show()

plt.figure(figsize=(6, 4))
plt.plot(df.index, df['infrared_property'], label='Infrared Property', color='blue')
plt.title('Line Graph of Infrared Property')
plt.xlabel('Index')
plt.ylabel('Infrared Property')
plt.legend()
plt.show()

sns.scatterplot(data=df, x='capacitive_property', y='moisture_property', hue='waste_type', palette='Set1')
plt.title('Capacitive vs Moisture Property')
plt.show()

sns.histplot(df['inductive_property'], kde=True, color='purple')
plt.title('Distribution of Inductive Property')
plt.show()

sns.boxplot(data=df, y='capacitive_property', color='lightblue')
plt.title('Outliers in Capacitive Property')
plt.show()

sns.countplot(data=df, x='waste_type', palette='Set3')
plt.title('Frequency of Waste Types')
plt.show()

df['waste_type'].value_counts(normalize=True) * 100

sns.ecdfplot(df['moisture_property'], color='red')
plt.title('Cumulative Distribution of Moisture Property')
plt.show()

from statsmodels.stats.outliers_influence import variance_inflation_factor

X = df.select_dtypes(include='number')
vif = pd.DataFrame()
vif['Feature'] = X.columns
vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
print(vif)

df.groupby('waste_type').agg(
    max_moisture=('moisture_property', 'max'),
    avg_moisture=('moisture_property', 'mean'),
    total_entries=('moisture_property', 'count')
)

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

df.var(numeric_only=True)

df

numeric_data = df.select_dtypes(include=np.number)
numeric_data['waste_type'] = df['waste_type']
grouped_data = numeric_data.groupby('waste_type').mean()
print(grouped_data)

df.groupby('waste_type').agg(['mean', 'median', 'std', 'min', 'max'])

df['waste_type_organic'] = df['waste_type'].apply(lambda x: True if x.lower() == 'organic' else False)

df['waste_type_recyclable'] = df['waste_type'].apply(lambda x: True if x.lower() == 'recyclable' else False)

df

print(df['waste_type_organic'].value_counts())

if 'timestamp' in df.columns:
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df['hour'] = df['timestamp'].dt.hour
    df['day_of_week'] = df['timestamp'].dt.dayofweek

label_encoder = LabelEncoder()
df['waste_type_organic'] = label_encoder.fit_transform(df['waste_type_organic'])
print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))

scaler = StandardScaler()
numerical_columns = ['inductive_property', 'capacitive_property', 'moisture_property', 'infrared_property', 'hour', 'day_of_week']
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

for feature in numerical_columns:
    plt.figure(figsize=(6, 4))
    sns.histplot(df[feature], kde=True, bins=30)
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')
    plt.show()

X = df.drop(columns=['waste_type_organic'])
y = df['waste_type_organic']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

for col in numerical_columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)
print(df[numerical_columns].describe())

df

from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("SMOTE input shape:", X.shape, y.shape)
print("SMOTE output shape:", X_resampled.shape, y_resampled.shape)

df.head()

df['inductive_capacitive'] = df['inductive_property'] * df['capacitive_property']
df['moisture_infrared'] = df['moisture_property'] * df['infrared_property']
print(df.head())

numeric_data = df.select_dtypes(include=np.number)
correlation_matrix = numeric_data.corr()
print(correlation_matrix)

plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

print(df['waste_type_organic'].value_counts())
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X, y = smote.fit_resample(X, y)
print(pd.Series(y).value_counts())

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X)
print(f"Shape of feature matrix before: {X.shape}, after: {X_poly.shape}")

from sklearn.decomposition import PCA
pca = PCA(n_components=0.95)
X_reduced = pca.fit_transform(X)
print(f"Shape before PCA: {X.shape}, after PCA: {X_reduced.shape}")

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
print(pd.DataFrame(X_scaled).describe())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)
print(f"Training size: {X_train.shape}, Testing size: {X_test.shape}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
rf_classifier = RandomForestClassifier(
    n_estimators=100,
    max_depth=None,
    random_state=42,
    class_weight='balanced'
)
rf_classifier.fit(X_train, y_train)
y_pred = rf_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

importances = rf_classifier.feature_importances_

feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

print("\nFeature Importances:")
print(feature_importances)

!pip install xgboost

import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
xgb_classifier = xgb.XGBClassifier(
    objective='binary:logistic',
    random_state=42,
    eval_metric='logloss'
)
xgb_classifier.fit(X_train, y_train)

y_pred = xgb_classifier.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))